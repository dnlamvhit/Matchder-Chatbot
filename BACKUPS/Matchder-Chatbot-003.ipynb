{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit #Find and stop existing Streamlit processes to avoid conflic\n",
        "ngrok.kill()\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)\n",
        "\n",
        "# Run Streamlit app\n",
        "#!streamlit run chatbot.py --server.port 8501 > /content/logs.txt 2>&1 &\n",
        "!python -u -m streamlit run chatbot.py --server.port 8501 > /content/logs.txt 2>&1 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo2AOwYKYRzg",
        "outputId": "2d25ada0-8c83-4495-df2f-d14432a808a5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://73ba-34-106-233-58.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.get_tunnels()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB2XohJwdgin",
        "outputId": "5916a62a-79db-4cea-adf8-310b1703dddb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<NgrokTunnel: \"https://bf78-34-106-243-150.ngrok-free.app\" -> \"http://localhost:8501\">]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -v \"DEBUG\" /content/logs.txt | grep -v \"INFO\" #exclude lines containing \"DEBUG\" and \"INFO\""
      ],
      "metadata": {
        "id": "JLJASaJsgDOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "ap7gHHd_PLnW",
        "outputId": "e3369111-dee2-4798-fae4-b2d510e509cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link 'root/': No such file or directory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37709a33-1d68-46c0-bc83-518d8dd82b9f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37709a33-1d68-46c0-bc83-518d8dd82b9f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secrets.toml to secrets.toml\n"
          ]
        }
      ],
      "source": [
        "!ln -s / root #Create a link to the root directory in Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!mkdir -p /root/.streamlit/\n",
        "!mv secrets.toml /root/.streamlit/\n",
        "# Create or update a config.toml file in the .streamlit directory with the logging level set to debug\n",
        "#!echo -e \"[logger]\\nlevel = 'debug'\" > /root/.streamlit/config.toml\n",
        "#!pip install -r requirements.txt\n",
        "!pip install streamlit pyngrok pandas openai pinecone-client python-dotenv supabase > /dev/null 2>&1\n",
        "from pyngrok import ngrok\n",
        "!ngrok config set --no-auth > /dev/null 2>&1\n",
        "!ngrok authtoken 2lu4WybNd7R2foCiwPxyKkrP8jw_5Nhf922w71PZQKxMRqj3Z > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfuMtA708V8C",
        "outputId": "7463b7d7-ecd5-44b8-816f-db9ad699ac3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting chatbot.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile chatbot.py\n",
        "import sys\n",
        "import logging\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logger = logging.getLogger()\n",
        "# Set the watchdog logger to suppress debug messages\n",
        "watchdog_logger = logging.getLogger(\"watchdog\")\n",
        "watchdog_logger.setLevel(logging.ERROR)\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"numexpr\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"pinecone_plugin_interface\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"hpack\").setLevel(logging.WARNING)\n",
        "print(\"Starting Streamlit App\", file=sys.stdout)\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from openai import OpenAI\n",
        "#import textwrap3 as textwrap\n",
        "import dotenv\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "import csv\n",
        "import json\n",
        "from supabase import create_client\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# For sending email\n",
        "# import sendgrid\n",
        "# from sendgrid import SendGridAPIClient\n",
        "# from sendgrid.helpers.mail import Mail\n",
        "# from joblib import load\n",
        "# For getting google sheet content\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# For update knowledge base\n",
        "# import Update_KB\n",
        "\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "\n",
        "try:\n",
        "    OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n",
        "    PINECONE_API_KEY = st.secrets[\"PINECONE_API_KEY\"]\n",
        "    SENDGRID_API_KEY = st.secrets[\"SENDGRID_API_KEY\"]\n",
        "    SUPABASE_KEY = st.secrets[\"SUPABASE_KEY\"]\n",
        "except Exception as e:\n",
        "    # Secrets not found in Streamlit, try loading from local .env file\n",
        "    load_dotenv()\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "    SENDGRID_API_KEY = os.getenv(\"SENDGRID_API_KEY\")\n",
        "    SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "    if not OPENAI_API_KEY or not PINECONE_API_KEY or not SENDGRID_API_KEY or not SUPABASE_KEY:\n",
        "        st.error(\"Environment file error or secrets not found!\")\n",
        "        st.error(e)\n",
        "# Set OpenAI API key\n",
        "client = OpenAI(api_key = OPENAI_API_KEY)\n",
        "\n",
        "index_name = 'cstugpt-kb'\n",
        "pc = Pinecone( # initialize connection to pinecone\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=\"us-west1-gcp-free\")\n",
        "try:\n",
        "    pincone_index = pc.Index(index_name) # connect to pinecone index\n",
        "except:\n",
        "    print(\"Could not connect to Pinecone\")\n",
        "    pincone_index = None\n",
        "\n",
        "supabase = create_client(\"https://ziaisnybjhkjcbprxava.supabase.co\", SUPABASE_KEY)\n",
        "product_category_list = [\"All\"]\n",
        "#def fetch_categories():\n",
        "# Fetches category names from the public.categories table and stores them in the global categories_list.\"\"\"\n",
        "  # global categories_list\n",
        "try:\n",
        "        # Query the categories table to fetch category names\n",
        "        response = supabase.table(\"categories\").select(\"name\").execute()\n",
        "        if response.data:\n",
        "            # Extract category names from the query result\n",
        "            product_category_list += [category['name'] for category in response.data]\n",
        "        else:\n",
        "            product_category_list = [\"No categories found\"]\n",
        "except Exception as e:\n",
        "        st.error(f\"Error fetching categories: {e}\")\n",
        "\n",
        "# Call the function to fetch categories when the app starts\n",
        "# fetch_categories()\n",
        "\n",
        "# Function to update filters\n",
        "def update_filters(function_args):\n",
        "    \"\"\"Parses user input and creates filters.\"\"\"\n",
        "    #allow_inspect_value = function_args.get(\"allow_inspect\")\n",
        "    #allow_inspect_value = \"Yes\" if allow_inspect_value is True else \"No\" if allow_inspect_value is False else None\n",
        "    st.session_state.deal_type = function_args.get(\"deal_type\", \"All\")\n",
        "    st.session_state.product_name = function_args.get(\"product_name\", \"\")\n",
        "    st.session_state.address = function_args.get(\"address\", \"\")\n",
        "    st.session_state.num_days = function_args.get(\"num_days\", 365)\n",
        "    st.session_state.condition = function_args.get(\"condition\", \"All\")\n",
        "    st.session_state.status = function_args.get(\"status\", \"All\")\n",
        "    st.session_state.allow_inspect = function_args.get(\"allow_inspect\", \"All\")\n",
        "    st.session_state.delivery_method = function_args.get(\"delivery_method\", \"All\")\n",
        "    st.session_state.min_price = function_args.get(\"min_price\", 0.0)\n",
        "    st.session_state.max_price = function_args.get(\"max_price\", 2000000000.0)\n",
        "    st.session_state.category_name = function_args.get(\"category_name\", \"All\")\n",
        "    st.session_state.product_description = function_args.get(\"product_description\", \"\")\n",
        "\n",
        "    filters = {\n",
        "        \"_category_name\": function_args.get(\"category_name\", None),\n",
        "        \"_product_description\": function_args.get(\"product_description\", None),\n",
        "        \"_deal_type\": function_args.get(\"deal_type\", None),\n",
        "        \"_min_price\": function_args.get(\"min_price\", None),\n",
        "        \"_max_price\": function_args.get(\"max_price\", None),\n",
        "        \"_condition\": function_args.get(\"condition\", None),\n",
        "        \"_status\": function_args.get(\"status\", None),\n",
        "        \"_product_name\": function_args.get(\"product_name\", None),\n",
        "        \"_allow_inspect\": function_args.get(\"allow_inspect\", None),\n",
        "        \"_delivery_method\": function_args.get(\"delivery_method\", None),\n",
        "        \"_address\": function_args.get(\"address\", None),\n",
        "        \"_num_days\": function_args.get(\"num_days\", None),\n",
        "    }\n",
        "    return filters\n",
        "\n",
        "# Function to fetch products\n",
        "def fetch_product(filters):\n",
        "    columns_to_display = [\"name\", \"description\", \"deal_type\", \"price\", \"published_at\", \"condition\",\n",
        "                          \"status\", \"rating\", \"allow_inspect\", \"delivery_method\", \"address\", \"quantity\", \"product_image_urls\"]\n",
        "    try:\n",
        "        product_data, count = supabase.rpc(\"filter_products\", filters).execute()\n",
        "        if product_data[1]:\n",
        "            products_list = []\n",
        "            # Construct the product display table\n",
        "            for item in product_data[1]:\n",
        "                if item.get(\"type\") == \"Buyer\":\n",
        "                    min_budget = item.get(\"min_budget\")\n",
        "                    max_budget = item.get(\"max_budget\")\n",
        "                    item[\"price\"] = f\"${min_budget} - ${max_budget}\" if min_budget and max_budget else \"\"\n",
        "                elif item.get(\"type\") == \"Seller\":\n",
        "                    price = item.get(\"price\")\n",
        "                    item[\"price\"] = f\"${price}\" if price is not None else \"\"\n",
        "\n",
        "                # Format dates and links\n",
        "                if \"published_at\" in item and item[\"published_at\"]:\n",
        "                    try:\n",
        "                        published_at_date = datetime.fromisoformat(item[\"published_at\"])\n",
        "                        now_utc = datetime.now(timezone.utc)\n",
        "                        days_since_posting = (now_utc - published_at_date).days\n",
        "                        item[\"published_at\"] = f\"{days_since_posting} days ago\"\n",
        "                    except ValueError:\n",
        "                        item[\"published_at\"] = \"Invalid date\"\n",
        "\n",
        "                # Create a link to Google Maps for the address\n",
        "                latitude = item.get(\"latitude\")\n",
        "                longitude = item.get(\"longitude\")\n",
        "                address = item.get(\"address\")\n",
        "                if latitude and longitude:\n",
        "                    map_url = f\"https://google.com/maps?q={latitude},{longitude}\"\n",
        "                    #item[\"address\"] = f\"<a href='{map_url}' target='_blank'>{address}</a>\"\n",
        "\n",
        "                # Add item to the product list\n",
        "                products_list.append({\n",
        "                    \"PRODUTCT NAME\": item.get('name', ''),\n",
        "                    \"DESCRIPTION\": item.get('description', ''),\n",
        "                    \"DATA PROVIDER\": item.get('deal_type', ''),\n",
        "                    \"PRICE\": item.get('price', ''),\n",
        "                    \"CONDITION\": item.get('condition', ''),\n",
        "                    \"STATUS\": item.get('status', ''),\n",
        "                    \"LISTING DURATION\": item.get('published_at', ''),\n",
        "                    \"INSPECTABLE\": item.get('allow_inspect', ''),\n",
        "                    \"DELIVERY METHOD\": item.get('delivery_method', ''),\n",
        "                    \"ADDRESS\": item.get('address', ''),\n",
        "                    \"MAP LINK\": map_url\n",
        "                })\n",
        "            df = pd.DataFrame(products_list)\n",
        "            # Add a sequence number column starting from 1\n",
        "            df.index = df.index + 1\n",
        "            df.index.name = 'No.'\n",
        "            return df\n",
        "        else:\n",
        "            return \"No products match your query.\"\n",
        "    except (ValueError, TypeError, Exception) as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Initialize history and state for chatbot\n",
        "\n",
        "# Initialize default values in session state (this only runs the first time)\n",
        "def initialize():\n",
        "  if 'initialized' not in st.session_state:\n",
        "    st.session_state.initialized = True\n",
        "    st.session_state.chat_history = []\n",
        "    st.session_state.prompt_history = [{\"role\": \"system\", \"content\": (\"You are Matchder marketing assistant. \"\n",
        "      \"If users search, buy or sell products, ask if they can clarify any unclear inputs. If no more info, confirm with them final query before calling search_product(). \"\n",
        "      \"If you have not enough info to answer their query, refer them to Matchder website dev.matchder.com\")}]\n",
        "    st.session_state.deal_type = \"All\"\n",
        "    st.session_state.product_name = \"\"\n",
        "    st.session_state.address = \"\"\n",
        "    st.session_state.num_days = 365\n",
        "    st.session_state.condition = \"All\"\n",
        "    st.session_state.status = \"All\"\n",
        "    st.session_state.allow_inspect = \"All\"\n",
        "    st.session_state.delivery_method = \"All\"\n",
        "    st.session_state.min_price = 0.0\n",
        "    st.session_state.max_price = 2000000000.0\n",
        "    st.session_state.category_name = \"All\"\n",
        "    st.session_state.product_description = \"\"\n",
        "initialize()\n",
        "# STREAMLIT INTERFACE\n",
        "with st.sidebar:\n",
        "  #st.sidebar.image(\"CSTU.png\", use_column_width=True)\n",
        "  #st.sidebar.image(\"robo.gif\", use_column_width=True)\n",
        "  # Set the text color and alignment for the selectbox label and options\n",
        "  st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .stSelectbox > label,\n",
        "    .stSelectbox > select {\n",
        "      color: darkblue;\n",
        "      font-weight: bold;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "  st.markdown(\"<font color='darkblue'><b><p style='font-size: 21px; text-align: center; line-height: 0;'>MATCHDER CHATBOT</p></b></font>\", unsafe_allow_html=True)\n",
        "  st.write(\"<font color='darkblue'><b><p style='text-align: center; line-height: 0;'>NEW CHAT SESSION</p></b></font>\", unsafe_allow_html=True)\n",
        "  col1, col2, col3 = st.columns([1, 1, 1])\n",
        "  with col2:\n",
        "    if st.button(\" üóëÔ∏è \"):\n",
        "      initialize()\n",
        "      st.rerun()\n",
        "  st.markdown(\"<font color='darkblue'><b><p style='text-align: center; line-height: 0;'>KNOWLEDGE-BASE SETUP</p></b></font>\", unsafe_allow_html=True)\n",
        "  n_KB = int(st.selectbox(\"Number of KB records to find/query:\", [\"1\", \"2\", \"3\", \"4\", \"5\"]))\n",
        "  # Create a menu\n",
        "  if 'index' not in st.session_state:\n",
        "      st.session_state['index'] = None\n",
        "  st.markdown(\"<font color='darkblue'><b><p style='text-align: center; line-height: 0;'>DATABASE MANAGEMENT</p></b></font>\", unsafe_allow_html=True)\n",
        "  options = st.selectbox(\n",
        "      'Choose a task option:',\n",
        "      ('UPDATE KNOWLEDGE-BASE', '', ''),\n",
        "      key='menu',\n",
        "      index = st.session_state['index']\n",
        "  )\n",
        "  if options is not None:\n",
        "      st.session_state['index'] = ('UPDATE KNOWLEDGE-BASE', '', '').index(options)\n",
        "      #expander=st.sidebar\n",
        "      if 'login_status' not in st.session_state:\n",
        "          st.session_state['login_status'] = False\n",
        "      st.session_state['key'] = 0\n",
        "      with st.expander:\n",
        "          username = st.text_input(\"Enter your username:\", key=st.session_state['key'])\n",
        "          password = st.text_input(\"Enter your password:\", type=\"password\", key=st.session_state['key']+1)\n",
        "          #upload_window = st.empty()\n",
        "          if st.button(\"LOGIN\"):\n",
        "              for user in st.secrets[\"admin_accounts\"].get(\"users\", []):\n",
        "                  if username == user.get(\"username\") and password == user.get(\"password\"):\n",
        "                      st.session_state['login_status'] = True\n",
        "                      st.balloons()\n",
        "                      break\n",
        "              if st.session_state['login_status'] == False:\n",
        "                  st.warning(\"Invalid username or password. Please try again!\")\n",
        "          if st.button(\"LOGOUT\"):\n",
        "              st.session_state['login_status'] = False\n",
        "              st.session_state['key'] += 2\n",
        "              st.session_state['index'] = None\n",
        "              st.rerun()\n",
        "          if st.session_state['login_status']:\n",
        "              if options == 'UPDATE KNOWLEDGE-BASE':\n",
        "                file_name = st.file_uploader(\"Select your pdf catalog file\", type=\"pdf\")\n",
        "                if file_name is not None:\n",
        "                    st_button=st.empty()\n",
        "                    if st_button.button(\"UPLOAD\"):\n",
        "                        st_button.empty()\n",
        "                        try:\n",
        "                              result=update_kb_openai()\n",
        "                              st.balloons()\n",
        "                              st.success(\"Knowledge-base records updated:\\n\"+result)\n",
        "                        except Exception as e:\n",
        "                              st.write(e)\n",
        "\n",
        "# Main interface\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .stChatInput > div {\n",
        "        border: 1px solid black !important;\n",
        "        border-radius: 10px !important;\n",
        "        resize: both !important;\n",
        "        overflow: auto !important;\n",
        "    }\n",
        "    .stButton > button {\n",
        "        width: 45px;\n",
        "        height: 45px;\n",
        "        font-size: 25px;}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "#with st.container():\n",
        "col1, col2 = st.columns([50, 1])\n",
        "with col1:\n",
        "    with st.expander(\"SEARCH FOR PRODUCT BASED ON USER-SELECTED FILTERS\"):\n",
        "      st.session_state.deal_type = st.radio(\"Are you looking for\", [\"Buyer\", \"Seller\", \"All\"],\n",
        "         index=[\"Buyer\", \"Seller\", \"All\"].index(st.session_state.deal_type) if st.session_state.deal_type in [\"Buyer\", \"Seller\", \"All\"] else 2)\n",
        "      st.session_state.product_name = st.text_input(\"Product Name\", value=st.session_state.product_name)\n",
        "      st.session_state.address = st.text_input(\"Address\", value=st.session_state.address)\n",
        "      st.session_state.num_days = st.number_input(\"Within number of days since advertised\", min_value=0, value=st.session_state.num_days)\n",
        "      st.session_state.condition = st.radio(\"Condition\", [\"All\", \"New\", \"Like New\", \"Excellent\", \"Good\", \"Fair\", \"Salvage\"],\n",
        "         index=[\"All\", \"New\", \"Like New\", \"Excellent\", \"Good\", \"Fair\", \"Salvage\"].index(st.session_state.condition) if st.session_state.condition in [\"All\", \"New\", \"Like New\", \"Excellent\", \"Good\", \"Fair\", \"Salvage\"] else 0)\n",
        "      st.session_state.status = st.radio(\"Status\", [\"All\", \"Available\", \"Sold out\", \"Still searching\", \"Bought\"],\n",
        "         index=[\"All\", \"Available\", \"Sold out\", \"Still searching\", \"Bought\"].index(st.session_state.status) if st.session_state.status in [\"All\", \"Available\", \"Sold out\", \"Still searching\", \"Bought\"] else 0)\n",
        "      allow_inspect_options = {\"All\": None, \"Yes\": True, \"No\": False}\n",
        "      allow_inspect_selection = st.radio(\"Pre-purchase Inspection Allowed\", [\"All\", \"Yes\", \"No\"],\n",
        "         index=[\"All\", \"Yes\", \"No\"].index(\"Yes\" if st.session_state.allow_inspect is True else \"No\" if st.session_state.allow_inspect is False else \"All\"))\n",
        "      st.session_state.allow_inspect = allow_inspect_options[allow_inspect_selection]  # Store the boolean value\n",
        "      st.session_state.delivery_method = st.radio(\"Delivery Method\", [\"All\", \"Pickup\", \"Delivery Driver\", \"Shipping\"],\n",
        "         index=[\"All\", \"Pickup\", \"Delivery Driver\", \"Shipping\"].index(st.session_state.delivery_method) if st.session_state.delivery_method in [\"All\", \"Pickup\", \"Delivery Driver\", \"Shipping\"] else 0)\n",
        "      st.session_state.min_price = st.number_input(\"Min Price\", min_value=0.0, value=float(st.session_state.min_price), format=\"%.2f\")\n",
        "      st.session_state.max_price = st.number_input(\"Max Price\", min_value=0.0, value=float(st.session_state.max_price), format=\"%.2f\")\n",
        "      st.session_state.category_name = st.selectbox(\"Category Name\", product_category_list,\n",
        "         index=product_category_list.index(st.session_state.category_name) if st.session_state.category_name in product_category_list else 0)\n",
        "      st.session_state.product_description = st.text_input(\"Product Description\", value=st.session_state.product_description)\n",
        "search_result = None\n",
        "with col2:\n",
        "    #st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
        "    #submit_button = st.markdown('<button title=\"Submit your question\"> ‚èé </button>', unsafe_allow_html=True)\n",
        "    #submit_button = st.button(\" ‚èé \", key=\"submit_button\")\n",
        "    #if st.markdown('<button title=\"Search products\">üîç</button>', unsafe_allow_html=True): #Search button\n",
        "    if st.button(\"üîç\", key=\"search_button\"):\n",
        "          def reverse_map(value):\n",
        "              \"\"\"Map 'All' and '' to None, 'Yes' to True, 'No' to False.\"\"\"\n",
        "              if value in [\"All\", \"\", 0]:\n",
        "                  return None\n",
        "              elif value == \"Yes\":\n",
        "                  return True\n",
        "              elif value == \"No\":\n",
        "                  return False\n",
        "              return value\n",
        "          filters = {\n",
        "              \"_category_name\": reverse_map(st.session_state.category_name),\n",
        "              \"_product_description\": reverse_map(st.session_state.product_description),\n",
        "              \"_deal_type\": reverse_map(st.session_state.deal_type),\n",
        "              \"_min_price\": reverse_map(st.session_state.min_price),\n",
        "              \"_max_price\": reverse_map(st.session_state.max_price),\n",
        "              \"_condition\": reverse_map(st.session_state.condition),\n",
        "              \"_status\": reverse_map(st.session_state.status),\n",
        "              \"_product_name\": reverse_map(st.session_state.product_name),\n",
        "              \"_allow_inspect\": reverse_map(st.session_state.allow_inspect),\n",
        "              \"_delivery_method\": reverse_map(st.session_state.delivery_method),\n",
        "              \"_address\": reverse_map(st.session_state.address),\n",
        "              \"_num_days\": reverse_map(st.session_state.num_days),\n",
        "          }\n",
        "          search_result = fetch_product(filters)\n",
        "if isinstance(search_result, pd.DataFrame):  # If it's a DataFrame, display it as a table\n",
        "    st.write(\"Products match your selected filters are listed as follows:\\n\")\n",
        "    st.dataframe(search_result, column_config={'MAP LINK': st.column_config.LinkColumn()})\n",
        "    st.write(\"________________________________________________________________________________________________________________\")\n",
        "    #st.markdown(search_result.to_html(escape=False, index=False), unsafe_allow_html=True)\n",
        "elif isinstance(search_result, str):  # If it's a text message, display the text\n",
        "    st.write(search_result)\n",
        "\n",
        "#st.markdown('<div class=\"chat-container\">', unsafe_allow_html=True)\n",
        "if st.session_state.chat_history:\n",
        "        for chat in st.session_state.chat_history:\n",
        "            with st.chat_message(chat[\"role\"]): #(\"user\" if chat[0] == \"user\" else \"assistant\"):\n",
        "                if chat[\"role\"] == \"user\": st.markdown(\"**YOU:**\")\n",
        "                elif chat[\"role\"] == \"assistant\": st.markdown(\"**MATCHDER:**\")\n",
        "                else: chat[\"role\"] == st.markdown(\"**SYSTEM:**\")\n",
        "                if isinstance(chat[\"content\"], list): # If it's a list of dic, display it as a table\n",
        "                    st.write(\"Products match your query are listed as follows:\\n\")\n",
        "                    st.dataframe(pd.Dataframe(chat[\"content\"]), column_config={'MAP LINK': st.column_config.LinkColumn()})\n",
        "                else: st.write(chat[\"content\"]) # If it's a text message, display the text\n",
        "#st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "#user_input = st.text_area(\"ENTER YOUR QUESTION\", placeholder=\"Type here ...\", key='user_input', height=1, help='Resize by dragging the bottom-right corner', max_chars=None,)\n",
        "user_input = st.chat_input(\"Type your question here ...\")\n",
        "\n",
        "# CHAT PROCESS\n",
        "# Chatbot function\n",
        "def chat(user_input):\n",
        "    st.session_state.prompt_history.insert(-1, {\"role\": \"user\", \"content\": user_input})\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    try:\n",
        "        response1 = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[msg for msg in st.session_state.prompt_history],\n",
        "            functions=[{\n",
        "                \"name\": \"search_product\",\n",
        "                \"description\": \"Search products from the database based on user input\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"category_name\": {\"type\": \"string\", \"description\": f\"Product category choosen from: {', '.join(product_category_list)}\"},\n",
        "                        \"product_name\": {\"type\": \"string\", \"description\": \"Product name\"},\n",
        "                        \"product_description\": {\"type\": \"string\", \"description\": \"Product description\"},\n",
        "                        \"deal_type\": {\"type\": \"string\", \"description\": \"deal_type is 'Seller' if user asks to buy/find items posted for sale, or 'Buyer' if user asks to sell/find items posted for purchase\"},\n",
        "                        \"min_price\": {\"type\": \"number\", \"description\": \"Product min price\"},\n",
        "                        \"max_price\": {\"type\": \"number\", \"description\": \"Product max price\"},\n",
        "                        \"condition\": {\"type\": \"string\", \"description\": \"Product condition: New, Like New, Excellent, Good, Fair, Salvage\"},\n",
        "                        \"status\": {\"type\": \"string\", \"description\": \"Product status: Available, Sold out, Still searching, Bought\"},\n",
        "                        \"allow_inspect\": {\"type\": \"boolean\", \"description\": \"Whether allow pre-purchase inspection\"},\n",
        "                        \"delivery_method\": {\"type\": \"string\", \"description\": \"Delivery method: Pickup, Delivery Driver, Shipping\"},\n",
        "                        \"address\": {\"type\": \"string\", \"description\": \"Address\"},\n",
        "                        \"num_days\": {\"type\": \"number\", \"description\": \"The maximum number of days since the product was posted, indicating that the user wants to search for products posted within this number of days from today\"},\n",
        "                    }\n",
        "                }\n",
        "            }]\n",
        "        )\n",
        "        print(response1.choices[0].message, file=sys.stdout)\n",
        "        st.write(response)\n",
        "        if response1.choices[0].finish_reason == \"function_call\":\n",
        "            function_name = response1.choices[0].message.function_call.name\n",
        "            function_args = json.loads(response1.choices[0].message.function_call.arguments)\n",
        "\n",
        "            if function_name == \"search_product\":\n",
        "                filters = update_filters(function_args)\n",
        "                search_result = fetch_product(filters)\n",
        "                if isinstance(search_result, pd.DataFrame): search_result = search_result.to_dict(orient='records')  # Convert DataFrame to a list of JSON-friendly dict\n",
        "                response2 = client.chat.completions.create(# Send the search result back to LLM to allow the model to reply to the user\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=[{\"role\": \"user\", \"content\": user_input},\n",
        "                              {\"role\": \"function\", \"name\": \"search_product\", \"content\": search_result}])\n",
        "                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response2.choices[0].message.content})\n",
        "                st.session_state.prompt_history.append({\"role\": \"assistant\", \"content\": response2.choices[0].message.content})\n",
        "                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": search_result})\n",
        "                st.session_state.prompt_history.append({\"role\": \"assistant\", \"content\": search_result})\n",
        "            else:\n",
        "                st.write((\"system\", f\"Unhandled function call: {function_name}\"))\n",
        "        content1 = response1.choices[0].message.content\n",
        "        if content1:\n",
        "            st.session_state.prompt_history.insert(-1, {\"role\": \"assistant\", \"content\": content1})\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": content1})\n",
        "    except Exception as e:\n",
        "        st.session_state.chat_history.append({\"role\": \"system\", \"content\": f\"An error occurred: {str(e)}\"})\n",
        "\n",
        "# Handle chat submission\n",
        "if user_input:\n",
        "  if user_input.strip() != \"\":\n",
        "    chat(user_input)\n",
        "    user_input = \"\"\n",
        "    st.rerun()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!streamlit run chatbot.py --server.address=localhost &>/content/logs.txt &\n",
        "!streamlit run chatbot.py --server.port=8501 &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501 --subdomain lamdao & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "UuTCGKR6Vufv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da11b32-f80d-4fb4-d57d-9bd61b74c839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.141.186.66\n",
            "your url is: https://lamdao.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep '[s]treamlit' #Checking running instance to kill it"
      ],
      "metadata": {
        "id": "OiIT6YFtwLKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit #Stop all running instance"
      ],
      "metadata": {
        "id": "DxJdZNlf4A04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill <process_id>"
      ],
      "metadata": {
        "id": "GSg9VFgcwdlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBKbAcCsqvo3",
        "outputId": "228461b5-e7c6-46c9-fef4-4a2e6440de70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-09-11T21:01:13+0000 lvl=warn msg=\"failed to open private leg\" id=8a74b34e77d3 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://e1e6-34-173-92-239.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8501, \"http\").public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Add logic to send a request with the ngrok-skip-browser-warning header\n",
        "headers = {\n",
        "    \"ngrok-skip-browser-warning\": \"true\"\n",
        "}\n",
        "\n",
        "# Make a GET request to the public URL with the custom header to bypass the warning\n",
        "response = requests.get(public_url, headers=headers)\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run chatbot.py &> /dev/null &"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delimiter = \"\"\n",
        "\"\"\"\n",
        "# Accept user input\n",
        "if user_input := st.chat_input(\"Enter a prompt here to ask me for information\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    if OPENAI_API_KEY:\n",
        "        # Word2Vector embedding\n",
        "        # input_emb=generate_embedding(embedding_model, user_input)\n",
        "        # OpenAI embedding\n",
        "        res = openai.Embedding.create(input=[user_input],engine=embedding_model)\n",
        "        input_emb=res['data'][0]['embedding']\n",
        "        kb_res = pincone_index.query(vector=input_emb, top_k=n_KB, include_metadata=True, namespace='cstu', metric=\"cosine\")\n",
        "        #If the include_metadata parameter is set to True, the query method will only return the id, score, and metadata for each document. The vector for each document will not be returned\n",
        "        metadata_text_list = [x['metadata']['text'] for x in kb_res['matches']]\n",
        "        limit = 3600  #set the limit of knowledge base words\n",
        "        kb_content = \" \"\n",
        "        count = 0\n",
        "        proceed = True\n",
        "        while proceed and count < len(metadata_text_list):  # append until hitting limit\n",
        "            if len(kb_content) + len(metadata_text_list[count]) >= limit:\n",
        "                proceed = False\n",
        "            else:\n",
        "                    kb_content += metadata_text_list[count]\n",
        "            count += 1\n",
        "\n",
        "        # Add knowledge base and user message to promt history\n",
        "        st.session_state.prompt_history.append({\"role\": \"system\", \"content\": f\"{delimiter}{kb_content}{delimiter}\"})\n",
        "        st.session_state.prompt_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Get the model response\n",
        "        response = chat_complete_messages(st.session_state.prompt_history, temperature=0)\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.chat_history:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            if isinstance(message[\"content\"], list):\n",
        "                st.write(\"Here is your results:\")\n",
        "                df = pd.DataFrame(message[\"content\"])\n",
        "                st.dataframe(df)\n",
        "            else:\n",
        "                st.markdown(message[\"content\"])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vNORQMyg5sDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4ab28e46-032e-48d0-f9ce-ee555defe6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Accept user input\\nif user_input := st.chat_input(\"Enter a prompt here to ask me for information\"):\\n    # Add user message to chat history\\n    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\\n    if OPENAI_API_KEY:\\n        # Word2Vector embedding\\n        # input_emb=generate_embedding(embedding_model, user_input)\\n        # OpenAI embedding\\n        res = openai.Embedding.create(input=[user_input],engine=embedding_model)\\n        input_emb=res[\\'data\\'][0][\\'embedding\\']\\n        kb_res = pincone_index.query(vector=input_emb, top_k=n_KB, include_metadata=True, namespace=\\'cstu\\', metric=\"cosine\")\\n        #If the include_metadata parameter is set to True, the query method will only return the id, score, and metadata for each document. The vector for each document will not be returned\\n        metadata_text_list = [x[\\'metadata\\'][\\'text\\'] for x in kb_res[\\'matches\\']]\\n        limit = 3600  #set the limit of knowledge base words\\n        kb_content = \" \"\\n        count = 0\\n        proceed = True\\n        while proceed and count < len(metadata_text_list):  # append until hitting limit\\n            if len(kb_content) + len(metadata_text_list[count]) >= limit:\\n                proceed = False\\n            else:\\n                    kb_content += metadata_text_list[count]\\n            count += 1\\n\\n        # Add knowledge base and user message to promt history\\n        st.session_state.prompt_history.append({\"role\": \"system\", \"content\": f\"{delimiter}{kb_content}{delimiter}\"})\\n        st.session_state.prompt_history.append({\"role\": \"user\", \"content\": user_input})\\n\\n        # Get the model response\\n        response = chat_complete_messages(st.session_state.prompt_history, temperature=0)\\n\\n# Display chat messages\\nfor message in st.session_state.chat_history:\\n        with st.chat_message(message[\"role\"]):\\n            if isinstance(message[\"content\"], list):\\n                st.write(\"Here is your results:\")\\n                df = pd.DataFrame(message[\"content\"])\\n                st.dataframe(df)\\n            else:\\n                st.markdown(message[\"content\"])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display chat history\n",
        "\"\"\"if \"chat_history\" in st.session_state:\n",
        "    for chat in st.session_state.chat_history:\n",
        "        with st.chat_message(\"user\" if chat[0] == \"user\" else \"assistant\"):\n",
        "            st.write(chat[1])\n",
        "for chat in st.session_state.chat_history:\n",
        "    if chat[0] == \"user\":\n",
        "        st.write(f\"**You**: {chat[1]}\")\n",
        "    elif chat[0] == \"assistant\":\n",
        "        st.write(f\"**Bot**: {chat[1]}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v5zYPn85rk1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}